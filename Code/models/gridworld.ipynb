{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/bryangonzalez/Documents/Dartmouth/Research/TheoryOfMind_Bx_experiment/Code/models/')\n",
    "sys.path.append('/Users/bryangonzalez/Documents/Dartmouth/Research/TheoryOfMind_Bx_experiment/Code/')\n",
    "\n",
    "import comp_models\n",
    "from utils import  soft_max, compute_aic, compute_bic\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.table import Table\n",
    "import pandas as pd\n",
    "\n",
    "dat = pd.read_csv('../../Data/bx_data.csv', index_col=0)\n",
    "game = dat.loc[dat.turker_id == 10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "WORLD_SIZE = 6#int( np.ceil( game.shape[0]/3 ))\n",
    "stepP = (.11 - (-.1))/WORLD_SIZE\n",
    "phi = np.arange(-0.1,.11, stepP).astype(float)\n",
    "phi.tolist().reverse()\n",
    "stepT = .51/WORLD_SIZE\n",
    "theta = np.arange(0, .51, stepT).astype(float)\n",
    "phi[np.floor(len(phi)/2).astype(int)]=0  #make sure the center is 0\n",
    "\n",
    "startState = [np.random.randint(0,WORLD_SIZE),np.random.randint(0,WORLD_SIZE)]\n",
    "\n",
    "discount = 0.39\n",
    "\n",
    "world = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
    "newWorld = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
    "# left, up, right, down\n",
    "actions = ['W', 'N', 'E', 'S', 'NE', 'NW', 'SE', 'SW','STAY']\n",
    "\n",
    "\n",
    "def MPM2(investment, multiplier, theta, phi):  # for param space simulations\n",
    "    x = np.unique(np.round(np.append(np.arange(0, int(multiplier) * int(investment), int(multiplier) * int(investment) / 10),int(multiplier * investment)))).astype(int)\n",
    "    pi = ((investment * multiplier) - x) / (investment * multiplier)  # Money kept by Trustee (as fraction of inv*mult)\n",
    "    expectation = investment * 2\n",
    "    guilt = ((expectation - x) / (investment * 4)) ** 2  # Guilt term\n",
    "    ie = (((investment * multiplier) - x) / ((investment * multiplier) + (10 - investment)) - .5) ** 2  # Inequity aversion term\n",
    "    u = theta * pi - (1 - theta) * (np.minimum(guilt + phi, ie - phi))  # Utility function\n",
    "    max_util = x[np.where(u == max(u))]\n",
    "    if len(max_util) > 1:\n",
    "        max_util = max_util[[0]]\n",
    "    if max_util.size == 0:\n",
    "        max_util = np.array([0])\n",
    "    # UNCOMMENT BELOW IF WORKING WITH SIMULATED DATA\n",
    "    # max_util = int(max_util) + np.random.normal(0.0, scale = noise)\n",
    "    return max_util\n",
    "\n",
    "\n",
    "def observeReward(t, i, j):\n",
    "    prediction = MPM2(investment=game.inv.iloc[t].astype('int'), multiplier=game.mult.iloc[t].astype('int'), theta= theta[j], phi=phi[i] )\n",
    "    pred = (prediction/game['im'][t]) * 100\n",
    "    observation = (game['ret'][t]/game['im'][t]) * 100\n",
    "    reward = ((100 - abs(pred - observation)) * .01) * 2 #times 2 may not be needed\n",
    "    return float(reward)\n",
    "\n",
    "\n",
    "def createRewardFunction(t):  #i is rows and j is columns\n",
    "    nextState = []\n",
    "    actionReward = []\n",
    "    for i in range(0, WORLD_SIZE):\n",
    "        nextState.append([])\n",
    "        actionReward.append([])\n",
    "        for j in range(0, WORLD_SIZE):\n",
    "            next = dict()\n",
    "            reward = dict()\n",
    "\n",
    "            next['STAY'] = [i,j]\n",
    "            reward['STAY'] = observeReward(t, i, j)\n",
    "\n",
    "            if i == 0:\n",
    "                next['N'] = [i, j]\n",
    "                reward['N'] = observeReward(t, i, j)\n",
    "            else:\n",
    "                next['N'] = [i - 1, j]\n",
    "                reward['N'] = observeReward(t, i-1, j)\n",
    "\n",
    "            if i == 0 and j == 0:\n",
    "                next['NW'] = [i,j]\n",
    "                reward['NW'] = observeReward(t, i, j)\n",
    "            elif i == 0:\n",
    "                next['NW'] = [i, j-1]\n",
    "                reward['NW'] = observeReward(t, i, j-1)\n",
    "            elif j == 0:\n",
    "                next['NW'] = [i-1, j]\n",
    "                reward['NW'] = observeReward(t, i-1, j)\n",
    "            else:\n",
    "                next['NW'] = [i-1, j-1]\n",
    "                reward['NW'] = observeReward(t, i-1, j-1)\n",
    "\n",
    "            if i == 0 and j == WORLD_SIZE - 1:\n",
    "                next['NE'] = [i, j]\n",
    "                reward['NE'] = observeReward(t, i, j)\n",
    "            elif i ==0:\n",
    "                next['NE'] = [i, j+1]\n",
    "                reward['NE'] = observeReward(t, i, j+1)\n",
    "            elif j == WORLD_SIZE-1:\n",
    "                next['NE'] = [i-1, j]\n",
    "                reward['NE'] = observeReward(t, i-1, j)\n",
    "            else:\n",
    "                next['NE'] = [i-1, j+1]\n",
    "                reward['NE'] = observeReward(t, i-1, j+1)\n",
    "\n",
    "            if i == WORLD_SIZE - 1 and j == 0:\n",
    "                next['SW'] = [i,j]\n",
    "                reward['SW'] = observeReward(t, i, j)\n",
    "            elif i == WORLD_SIZE - 1:\n",
    "                next['SW'] = [i, j-1]\n",
    "                reward['SW'] = observeReward(t, i, j-1)\n",
    "            elif j == 0:\n",
    "                next['SW'] = [i+1, j]\n",
    "                reward['SW'] = observeReward(t, i+1, j)\n",
    "            else:\n",
    "                next['SW'] = [i+1, j-1]\n",
    "                reward['SW'] = observeReward(t, i+1, j-1)\n",
    "\n",
    "            if i == WORLD_SIZE - 1 and j == WORLD_SIZE - 1:\n",
    "                next['SE'] = [i, j]\n",
    "                reward['SE'] = observeReward(t, i, j)\n",
    "            elif i == WORLD_SIZE - 1:\n",
    "                next['SE'] = [i, j+1]\n",
    "                reward['SE'] = observeReward(t, i, j+1)\n",
    "            elif j == WORLD_SIZE-1:\n",
    "                next['SE'] = [i+1, j]\n",
    "                reward['SE'] = observeReward(t, i+1, j)\n",
    "            else:\n",
    "                next['SE'] = [i+1, j+1]\n",
    "                reward['SE'] = observeReward(t, i+1, j+1)\n",
    "\n",
    "\n",
    "            if i == WORLD_SIZE - 1:\n",
    "                next['S'] = [i, j]\n",
    "                reward['S'] = observeReward(t, i, j)\n",
    "            else:\n",
    "                next['S'] = [i + 1, j]\n",
    "                reward['S'] = observeReward(t, i+1, j)\n",
    "\n",
    "            if j == 0:\n",
    "                next['W'] = [i, j]\n",
    "                reward['W'] = observeReward(t, i, j)\n",
    "            else:\n",
    "                next['W'] = [i, j - 1]\n",
    "                reward['W'] = observeReward(t, i, j-1)\n",
    "\n",
    "            if j == WORLD_SIZE - 1:\n",
    "                next['E'] = [i, j]\n",
    "                reward['E'] = observeReward(t,i,j)\n",
    "            else:\n",
    "                next['E'] = [i, j + 1]\n",
    "                reward['E'] = observeReward(t, i, j+1)\n",
    "\n",
    "\n",
    "            nextState[i].append(next)\n",
    "            actionReward[i].append(reward)\n",
    "    return nextState, actionReward\n",
    "\n",
    "\n",
    "def optimalPolicy(world):\n",
    "    while True:\n",
    "        # keep iteration until convergence\n",
    "        newWorld = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
    "        for i in range(0, WORLD_SIZE):\n",
    "            for j in range(0, WORLD_SIZE):\n",
    "                values = []\n",
    "                for action in actions:\n",
    "                    newPosition = nextState[i][j][action]\n",
    "                    # value iteration\n",
    "                    values.append(actionReward[i][j][action] + discount * world[newPosition[0], newPosition[1]])\n",
    "                newWorld[i][j] = np.max(values)\n",
    "        if np.sum(np.abs(world - newWorld)) < 1e-4:\n",
    "            print('Optimal Policy')\n",
    "            #draw_image(np.round(newWorld, decimals=2))\n",
    "            break\n",
    "        world = newWorld\n",
    "\n",
    "    return world\n",
    "\n",
    "\n",
    "\n",
    "# starting with a random (uncontrolled) policy such that P(action|state) is uniform )\n",
    "actionProb = []\n",
    "for i in range(0, WORLD_SIZE):\n",
    "    actionProb.append([])\n",
    "    for j in range(0, WORLD_SIZE):\n",
    "        actionProb[i].append(dict({'W': 1/len(actions), 'N': 1/len(actions), 'E': 1/len(actions), 'S': 1/len(actions),\n",
    "                                   'SE': 1/len(actions), 'SW': 1/len(actions), 'NE': 1/len(actions), 'NW':1/len(actions),\n",
    "                                   'STAY': 1/len(actions)}))\n",
    "\n",
    "\n",
    "chosenAct = []\n",
    "currstate = startState"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizing policy for trial 0\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 1\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 2\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 3\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 4\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 5\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 6\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 7\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 8\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 9\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 10\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 11\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 12\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 13\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 14\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 15\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 16\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 17\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 18\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 19\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 20\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 21\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 22\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 23\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 24\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 25\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 26\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 27\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 28\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 29\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 30\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 31\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 32\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 33\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 34\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 35\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 36\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 37\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 38\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 39\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 40\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 41\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 42\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 43\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 44\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 45\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 46\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 47\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 48\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 49\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 50\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 51\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 52\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 53\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 54\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 55\n",
      "Optimal Policy\n",
      "agent moved W\n",
      "optimizing policy for trial 56\n",
      "Optimal Policy\n",
      "agent moved W\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for t in np.arange(game.shape[0]):\n",
    "    print('optimizing policy for trial', t)\n",
    "    nextState, actionReward = createRewardFunction(t)\n",
    "    world = optimalPolicy(world)\n",
    "    # find the next move\n",
    "    # look up and choose the action with the highest value\n",
    "\n",
    "    chosenAct.append(max(actionReward[currstate[0]][currstate[1]]))\n",
    "    currstate = nextState[currstate[0]][currstate[1]][chosenAct[t]]\n",
    "    print('agent moved '+chosenAct[t])\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "g = sns.heatmap(world)\n",
    "g.invert_yaxis()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryangonzalez/Documents/Dartmouth/Research/TheoryOfMind_Bx_experiment/Code/utils.py:27: RuntimeWarning: overflow encountered in exp\n",
      "  e_x = np.exp(np.divide(np.array(x), tau))\n",
      "/Users/bryangonzalez/Documents/Dartmouth/Research/TheoryOfMind_Bx_experiment/Code/utils.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  r = np.divide(e_x, e_x.sum(axis=0))\n"
     ]
    }
   ],
   "source": [
    "n_states = 6\n",
    "alpha = discount\n",
    "#def mentalState_space(game, alpha, tau, n_states):\n",
    "decimals = int(np.log10(n_states) + 1)\n",
    "#phi = np.around(np.arange(-0.1, 0.10001, 0.2 / n_states).astype('float'), decimals=decimals)\n",
    "phi = np.linspace(-.1, .1, n_states)\n",
    "theta = np.linspace(0, .5, n_states)\n",
    "#theta = np.around(np.arange(0, .50001, .5 / n_states).astype('float'), decimals=decimals)\n",
    "p_strat = pd.DataFrame(data=1/(n_states**2), columns=theta, index=phi)\n",
    "counterfactuals = pd.DataFrame(columns=theta, index=phi)\n",
    "pred_err = pd.DataFrame(columns=theta, index=phi)  # hypothetical/counterfactual prediction errors\n",
    "first_guess = (theta[np.random.randint(len(theta))], phi[np.random.randint(len(phi))])  # initialize randomly\n",
    "mb_pred_bx = np.zeros(len(game))  # model predicted behavior\n",
    "future_state = np.nan\n",
    "# string state-space into vector\n",
    "tempStates = [[(thay, phii) for thay in theta] for phii in phi]\n",
    "states = [x for l in tempStates for x in l] # [row1a, row1b,..row2a, row2b...]\n",
    "for t in np.arange(len(game)):\n",
    "    if t == 0:\n",
    "        mb_pred_bx[0] = comp_models.mp_model_ppsoe(inv=game.inv.iloc[0], mult=game.mult.iloc[0],\n",
    "                                       theta=first_guess[0], phi=first_guess[1])\n",
    "    else:\n",
    "        mb_pred_bx[t] = comp_models.mp_model_ppsoe(inv=game.inv.iloc[0], mult=game.mult.iloc[0],\n",
    "                                       theta=future_state[0], phi=future_state[1])\n",
    "    for theyta in theta:\n",
    "        for phee in phi:\n",
    "            counterfactuals[theyta][phee] = comp_models.mp_model_ppsoe(inv=game.inv.iloc[t], mult=game.mult.iloc[t], theta=theyta, phi=phee)\n",
    "            pred_err[theyta][phee] = abs(game.ret.iloc[t] - counterfactuals[theyta][phee])  # counterfactual predictions errors\n",
    "            # probability update\n",
    "            p_strat[theyta][phee] = p_strat[theyta][phee] + alpha * ((1 - (pred_err[theyta][phee] / (game.im.iloc[t]))) - p_strat[theyta][phee])\n",
    "    #vectorize probabilities\n",
    "    tempProb = [[p_strat[thay][phe] for thay in theta] for phe in phi]  # [[row1][row2]....\n",
    "    prob = [x for l in  tempProb for x in l ] # [row1a, row1b, row1c..row2a, row2b...]\n",
    "    temp = soft_max(prob, .001)\n",
    "    future_state = states[np.random.choice(np.arange(len(states)), p=temp)]\n",
    "#    return mb_pred_bx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7feb72a2fc10>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(p_strat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-af21bf38",
   "language": "python",
   "display_name": "PyCharm (TheoryOfMind_Bx_experiment)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}